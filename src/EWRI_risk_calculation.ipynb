{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EWRI - Wildfire Risk Calculation\n",
    "**`risk_enhanced` = EWRI score (Embeddings × Vulnerability)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS & IMPORTS\n",
    "COUNTY = \"napa\"  # Options: los_angeles, napa, suffolk, maricopa\n",
    "PRE_FIRE_YEARS = [2017, 2018, 2019]\n",
    "\n",
    "import pandas as pd, geopandas as gpd, numpy as np, h3, glob, os\n",
    "from shapely.geometry import Point\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE = \"/home/network-lab/Desktop/EWRI\"\n",
    "PROCESSED = f\"{BASE}/processed/{COUNTY}\"\n",
    "RAW = f\"{BASE}/raw/{COUNTY}\"\n",
    "OUTPUT = f\"{BASE}/outputs/{COUNTY}\"\n",
    "os.makedirs(OUTPUT, exist_ok=True)\n",
    "\n",
    "print(f\"County: {COUNTY.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA (4 parquet files)\n",
    "emb = pd.read_parquet(f\"{PROCESSED}/embeddings_h3.parquet\")\n",
    "sat = pd.read_parquet(f\"{PROCESSED}/satellite_h3.parquet\")\n",
    "fema = pd.read_parquet(f\"{PROCESSED}/fema_h3.parquet\")[[\"h3_index\", \"SOVI_SCORE\"]]\n",
    "exposure = pd.read_parquet(f\"{PROCESSED}/exposure_h3.parquet\")\n",
    "\n",
    "print(f\"Embeddings: {emb.shape}\")\n",
    "print(f\"Satellite: {sat.shape}\")\n",
    "print(f\"FEMA: {fema.shape}\")\n",
    "print(f\"Exposure: {exposure.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER EMBEDDINGS TO PRE-FIRE YEARS & MERGE ALL\n",
    "emb_cols = [\"h3_index\"] + [c for c in emb.columns if any(c.endswith(f\"_{y}\") for y in PRE_FIRE_YEARS)]\n",
    "emb = emb[emb_cols]\n",
    "print(f\"Embeddings filtered: {len(emb_cols)-1} features\")\n",
    "\n",
    "# Merge: inner(emb+sat), left(exposure), left(fema)\n",
    "df = emb.merge(sat, on=\"h3_index\", how=\"inner\")\n",
    "df = df.merge(exposure, on=\"h3_index\", how=\"left\")\n",
    "df = df.merge(fema, on=\"h3_index\", how=\"left\")\n",
    "print(f\"Merged: {len(df):,} hexagons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL BURNED HEXAGONS\n",
    "fire_files = glob.glob(f\"{RAW}/fire_data/*.shp\") + glob.glob(f\"{RAW}/fire_data/*.geojson\")\n",
    "fire = gpd.read_file(fire_files[0]).to_crs(\"EPSG:4326\")\n",
    "fire_union = fire.union_all()\n",
    "\n",
    "df[\"geometry\"] = [Point(*h3.cell_to_latlng(h)[::-1]) for h in tqdm(df[\"h3_index\"], desc=\"H3→Point\")]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "df[\"burned\"] = gdf.within(fire_union).astype(int)\n",
    "df = df.drop(columns=[\"geometry\"])\n",
    "\n",
    "print(f\"Burned: {df['burned'].sum():,} ({df['burned'].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE FEATURES & CREATE VULNERABILITY\n",
    "emb_cols = [c for c in df.columns if c.startswith(\"A\") and \"_\" in c]\n",
    "sat_cols = [c for c in df.columns if c not in emb_cols + [\"h3_index\",\"burned\",\"SOVI_SCORE\",\"pop_2017\",\"pop_2018\",\"pop_2019\",\"built_up\"]]\n",
    "\n",
    "for col in emb_cols + sat_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "    if df[col].max() > df[col].min():\n",
    "        df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "df['pop_avg'] = (df['pop_2017'].fillna(0) + df['pop_2018'].fillna(0) + df['pop_2019'].fillna(0)) / 3\n",
    "df['pop_norm'] = (df['pop_avg'] - df['pop_avg'].min()) / (df['pop_avg'].max() - df['pop_avg'].min() + 1e-9)\n",
    "df['building_norm'] = (df['built_up'].fillna(0) - df['built_up'].min()) / (df['built_up'].max() - df['built_up'].min() + 1e-9)\n",
    "df['sovi_norm'] = (df['SOVI_SCORE'] - df['SOVI_SCORE'].min()) / (df['SOVI_SCORE'].max() - df['SOVI_SCORE'].min() + 1e-9)\n",
    "df['sovi_norm'] = df['sovi_norm'].fillna(df['sovi_norm'].median())\n",
    "df['vulnerability'] = 0.45*df['pop_norm'] + 0.45*df['building_norm'] + 0.10*df['sovi_norm']\n",
    "print(f\"Vulnerability: min={df['vulnerability'].min():.4f}, max={df['vulnerability'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRE SIGNATURES & HAZARD SCORES\n",
    "burned_df = df[df[\"burned\"] == 1]\n",
    "print(f\"Using {len(burned_df):,} burned hexagons for signature\")\n",
    "\n",
    "sat_sig = burned_df[sat_cols].mean().values.reshape(1, -1)\n",
    "emb_sig = burned_df[emb_cols].mean().values.reshape(1, -1)\n",
    "\n",
    "df[\"hazard_baseline\"] = cosine_similarity(df[sat_cols].values, sat_sig).flatten()\n",
    "df[\"hazard_enhanced\"] = cosine_similarity(df[emb_cols].values, emb_sig).flatten()\n",
    "\n",
    "print(f\"hazard_baseline: {df['hazard_baseline'].min():.4f} to {df['hazard_baseline'].max():.4f}\")\n",
    "print(f\"hazard_enhanced: {df['hazard_enhanced'].min():.4f} to {df['hazard_enhanced'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RISK SCORES\n",
    "df[\"risk_baseline\"] = df[\"hazard_baseline\"] * df[\"vulnerability\"]\n",
    "df[\"risk_enhanced\"] = df[\"hazard_enhanced\"] * df[\"vulnerability\"]\n",
    "\n",
    "df[\"risk_category\"] = pd.cut(df[\"risk_enhanced\"].rank(pct=True), \n",
    "                              bins=[0,0.5,0.7,0.9,1], labels=[\"Low\",\"Moderate\",\"High\",\"Very High\"])\n",
    "print(df[\"risk_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION (AUC + Fire Capture @ 20%)\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"VALIDATION - {COUNTY.upper()}\")\n",
    "print(f\"{'='*50}\")\n",
    "auc_s = roc_auc_score(df['burned'], df['hazard_baseline'])\n",
    "auc_e = roc_auc_score(df['burned'], df['hazard_enhanced'])\n",
    "fc_s = df[df['hazard_baseline'] >= df['hazard_baseline'].quantile(0.8)]['burned'].sum() / df['burned'].sum() * 100\n",
    "fc_e = df[df['hazard_enhanced'] >= df['hazard_enhanced'].quantile(0.8)]['burned'].sum() / df['burned'].sum() * 100\n",
    "print(f\"AUC-ROC:  Satellite={auc_s:.4f}  Embeddings={auc_e:.4f}  (Δ +{(auc_e-auc_s)/auc_s*100:.0f}%)\")\n",
    "print(f\"FC@20%:   Satellite={fc_s:.1f}%     Embeddings={fc_e:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE OUTPUT\n",
    "output_cols = [\"h3_index\",\"hazard_baseline\",\"hazard_enhanced\",\"vulnerability\",\n",
    "               \"risk_baseline\",\"risk_enhanced\",\"risk_category\",\"burned\"]\n",
    "output = df[output_cols]\n",
    "output_path = f\"{OUTPUT}/{COUNTY}_EWRI_final.csv\"\n",
    "output.to_csv(output_path, index=False)\n",
    "print(f\"✓ Saved: {output_path} ({len(output):,} hexagons)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "THESIS RESULTS: AUC-ROC & Fire Capture @ 20%\n",
      "===========================================================================\n",
      "County        Fire%  AUC(Sat)  AUC(Emb)      Δ  FC@20(S)  FC@20(E)\n",
      "---------------------------------------------------------------------------\n",
      "los_angeles    2.4%      0.87      0.91    +5%       71%       89%\n",
      "napa           2.2%      0.68      0.82   +20%       44%       68%\n",
      "suffolk        2.3%      0.65      0.77   +19%       44%       52%\n",
      "maricopa       1.8%      0.69      0.93   +34%       57%       89%\n",
      "---------------------------------------------------------------------------\n",
      "AVERAGE                  0.72      0.86   +19%       54%       75%\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ALL COUNTIES SUMMARY (Run after processing all 4)\n",
    "print(\"=\"*75)\n",
    "print(\"THESIS RESULTS: AUC-ROC & Fire Capture @ 20%\")\n",
    "print(\"=\"*75)\n",
    "print(f\"{'County':<12} {'Fire%':>6} {'AUC(Sat)':>9} {'AUC(Emb)':>9} {'Δ':>6} {'FC@20(S)':>9} {'FC@20(E)':>9}\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "aucs_s, aucs_e, fcs_s, fcs_e = [], [], [], []\n",
    "for county in [\"los_angeles\", \"napa\", \"suffolk\", \"maricopa\"]:\n",
    "    path = f\"{BASE}/outputs/{county}/{county}_EWRI_final.csv\"\n",
    "    if os.path.exists(path):\n",
    "        d = pd.read_csv(path)\n",
    "        a_s = roc_auc_score(d['burned'], d['hazard_baseline'])\n",
    "        a_e = roc_auc_score(d['burned'], d['hazard_enhanced'])\n",
    "        f_s = d[d['hazard_baseline'] >= d['hazard_baseline'].quantile(0.8)]['burned'].sum() / d['burned'].sum() * 100\n",
    "        f_e = d[d['hazard_enhanced'] >= d['hazard_enhanced'].quantile(0.8)]['burned'].sum() / d['burned'].sum() * 100\n",
    "        print(f\"{county:<12} {d['burned'].mean()*100:>5.1f}% {a_s:>9.2f} {a_e:>9.2f} {'+'+str(int((a_e-a_s)/a_s*100))+'%':>6} {f_s:>8.0f}% {f_e:>8.0f}%\")\n",
    "        aucs_s.append(a_s); aucs_e.append(a_e); fcs_s.append(f_s); fcs_e.append(f_e)\n",
    "    else:\n",
    "        print(f\"{county:<12} {'—':>6} {'—':>9} {'—':>9} {'—':>6} {'—':>9} {'—':>9}\")\n",
    "\n",
    "print(\"-\"*75)\n",
    "if aucs_s:\n",
    "    print(f\"{'AVERAGE':<12} {'':>6} {np.mean(aucs_s):>9.2f} {np.mean(aucs_e):>9.2f} {'+'+str(int((np.mean(aucs_e)-np.mean(aucs_s))/np.mean(aucs_s)*100))+'%':>6} {np.mean(fcs_s):>8.0f}% {np.mean(fcs_e):>8.0f}%\")\n",
    "print(\"=\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
