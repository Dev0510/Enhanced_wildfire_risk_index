{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings TIF → H3 Conversion (Chunked)\n",
    "Convert AlphaEarth Foundation Embeddings GeoTIFF to H3 parquet format.\n",
    "\n",
    "**Uses chunked processing to avoid memory issues.**\n",
    "\n",
    "**Change `COUNTY` below and run all cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County: MARICOPA\n",
      "H3 Resolution: 9\n",
      "Chunks: 10\n"
     ]
    }
   ],
   "source": [
    "# SETTINGS\n",
    "COUNTY = \"maricopa\"  # Options: los_angeles, napa, suffolk, maricopa\n",
    "H3_RES = 9              # H3 resolution (~174m hexagons)\n",
    "NUM_CHUNKS = 10         # Split into 10 chunks to save memory\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h3\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "BASE = \"/home/network-lab/Desktop/EWRI\"\n",
    "RAW = f\"{BASE}/raw/{COUNTY}/embeddings_data\"\n",
    "PROCESSED = f\"{BASE}/processed/{COUNTY}\"\n",
    "os.makedirs(PROCESSED, exist_ok=True)\n",
    "\n",
    "print(f\"County: {COUNTY.upper()}\")\n",
    "print(f\"H3 Resolution: {H3_RES}\")\n",
    "print(f\"Chunks: {NUM_CHUNKS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 TIF file(s)\n",
      "Using 5 file(s):\n",
      "  - Maricopa_embeddings_100m_2017_2024-0000000000-0000000000.tif: 512 bands, 1024x1024px\n",
      "  - Maricopa_embeddings_100m_2017_2024-0000000000-0000001024.tif: 512 bands, 1024x1024px\n",
      "  - Maricopa_embeddings_100m_2017_2024-0000000000-0000002048.tif: 512 bands, 507x1024px\n",
      "  - Maricopa_embeddings_100m_2017_2024-0000001024-0000000000.tif: 512 bands, 1024x695px\n",
      "  - Maricopa_embeddings_100m_2017_2024-0000001024-0000001024.tif: 512 bands, 1024x695px\n"
     ]
    }
   ],
   "source": [
    "# LIST TIF FILES\n",
    "tif_files = sorted(glob.glob(f\"{RAW}/*.tif\"))\n",
    "\n",
    "# Prefer merged file if exists, else use all tiles\n",
    "merged = [f for f in tif_files if \"merged\" in f.lower()]\n",
    "tif_to_use = merged if merged else tif_files\n",
    "\n",
    "print(f\"Found {len(tif_files)} TIF file(s)\")\n",
    "print(f\"Using {len(tif_to_use)} file(s):\")\n",
    "for f in tif_to_use:\n",
    "    with rasterio.open(f) as src:\n",
    "        print(f\"  - {os.path.basename(f)}: {src.count} bands, {src.width}x{src.height}px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band names: ['A00_2017', 'A01_2017', 'A02_2017'] ... ['A61_2024', 'A62_2024', 'A63_2024']\n",
      "Total: 512 bands\n"
     ]
    }
   ],
   "source": [
    "# GENERATE BAND NAMES (512 bands = 64 features x 8 years: 2017-2024)\n",
    "band_names = []\n",
    "for year in range(2017, 2025):\n",
    "    for i in range(64):\n",
    "        band_names.append(f\"A{i:02d}_{year}\")\n",
    "\n",
    "print(f\"Band names: {band_names[:3]} ... {band_names[-3:]}\")\n",
    "print(f\"Total: {len(band_names)} bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TILE 1/5: Maricopa_embeddings_100m_2017_2024-0000000000-0000000000.tif\n",
      "============================================================\n",
      "  Rows: 1024, Chunk size: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C1: 100%|██████████| 103/103 [00:06<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk00.parquet: 36,934 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C2: 100%|██████████| 103/103 [00:06<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk01.parquet: 101,734 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C3: 100%|██████████| 103/103 [00:09<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk02.parquet: 105,391 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C4: 100%|██████████| 103/103 [00:06<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk03.parquet: 105,382 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C5: 100%|██████████| 103/103 [00:09<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk04.parquet: 105,369 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C6: 100%|██████████| 103/103 [00:06<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk05.parquet: 105,388 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C7: 100%|██████████| 103/103 [00:06<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk06.parquet: 105,444 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C8: 100%|██████████| 103/103 [00:09<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk07.parquet: 105,369 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C9: 100%|██████████| 103/103 [00:06<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk08.parquet: 105,399 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T1C10: 100%|██████████| 97/97 [00:06<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile00_chunk09.parquet: 99,231 records\n",
      "\n",
      "============================================================\n",
      "TILE 2/5: Maricopa_embeddings_100m_2017_2024-0000000000-0000001024.tif\n",
      "============================================================\n",
      "  Rows: 1024, Chunk size: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C1: 100%|██████████| 103/103 [00:06<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk00.parquet: 52,052 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C2: 100%|██████████| 103/103 [00:06<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk01.parquet: 93,313 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C3: 100%|██████████| 103/103 [00:09<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk02.parquet: 105,472 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C4: 100%|██████████| 103/103 [00:06<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk03.parquet: 105,472 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C5: 100%|██████████| 103/103 [00:09<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk04.parquet: 105,472 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C6: 100%|██████████| 103/103 [00:06<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk05.parquet: 105,472 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C7: 100%|██████████| 103/103 [00:06<00:00, 15.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk06.parquet: 98,695 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C8: 100%|██████████| 103/103 [00:09<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk07.parquet: 95,447 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C9: 100%|██████████| 103/103 [00:06<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk08.parquet: 91,022 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T2C10: 100%|██████████| 97/97 [00:02<00:00, 37.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile01_chunk09.parquet: 30,473 records\n",
      "\n",
      "============================================================\n",
      "TILE 3/5: Maricopa_embeddings_100m_2017_2024-0000000000-0000002048.tif\n",
      "============================================================\n",
      "  Rows: 1024, Chunk size: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C1: 100%|██████████| 103/103 [00:02<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk00.parquet: 3,034 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C2: 100%|██████████| 103/103 [00:01<00:00, 95.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk01.parquet: 8,426 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C3: 100%|██████████| 103/103 [00:02<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk02.parquet: 12,695 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C4: 100%|██████████| 103/103 [00:01<00:00, 66.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk03.parquet: 16,505 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C5: 100%|██████████| 103/103 [00:03<00:00, 26.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk04.parquet: 34,854 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C6: 100%|██████████| 103/103 [00:03<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk05.parquet: 47,706 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C7: 100%|██████████| 103/103 [00:01<00:00, 69.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk06.parquet: 15,686 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C8: 100%|██████████| 103/103 [00:01<00:00, 55.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk07.parquet: 0 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C9: 100%|██████████| 103/103 [00:00<00:00, 178.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk08.parquet: 0 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T3C10: 100%|██████████| 97/97 [00:00<00:00, 181.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile02_chunk09.parquet: 0 records\n",
      "\n",
      "============================================================\n",
      "TILE 4/5: Maricopa_embeddings_100m_2017_2024-0000001024-0000000000.tif\n",
      "============================================================\n",
      "  Rows: 695, Chunk size: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C1: 100%|██████████| 70/70 [00:07<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk00.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C2: 100%|██████████| 70/70 [00:04<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk01.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C3: 100%|██████████| 70/70 [00:04<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk02.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C4: 100%|██████████| 70/70 [00:06<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk03.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C5: 100%|██████████| 70/70 [00:04<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk04.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C6: 100%|██████████| 70/70 [00:04<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk05.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C7: 100%|██████████| 70/70 [00:04<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk06.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C8: 100%|██████████| 70/70 [00:06<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk07.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C9: 100%|██████████| 70/70 [00:04<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk08.parquet: 71,610 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4C10: 100%|██████████| 65/65 [00:03<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile03_chunk09.parquet: 66,326 records\n",
      "\n",
      "============================================================\n",
      "TILE 5/5: Maricopa_embeddings_100m_2017_2024-0000001024-0000001024.tif\n",
      "============================================================\n",
      "  Rows: 695, Chunk size: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C1: 100%|██████████| 70/70 [00:04<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk00.parquet: 16,660 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C2: 100%|██████████| 70/70 [00:01<00:00, 47.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk01.parquet: 16,632 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C3: 100%|██████████| 70/70 [00:01<00:00, 47.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk02.parquet: 16,588 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C4: 100%|██████████| 70/70 [00:03<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk03.parquet: 16,520 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C5: 100%|██████████| 70/70 [00:01<00:00, 47.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk04.parquet: 16,520 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C6: 100%|██████████| 70/70 [00:01<00:00, 45.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk05.parquet: 16,520 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C7: 100%|██████████| 70/70 [00:01<00:00, 47.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk06.parquet: 16,520 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C8: 100%|██████████| 70/70 [00:03<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk07.parquet: 16,520 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C9: 100%|██████████| 70/70 [00:01<00:00, 44.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk08.parquet: 16,520 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T5C10: 100%|██████████| 65/65 [00:01<00:00, 46.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ tile04_chunk09.parquet: 14,952 records\n",
      "\n",
      "✓ All 50 chunks saved!\n"
     ]
    }
   ],
   "source": [
    "# CHUNKED CONVERSION - Process in parts to save memory\n",
    "# FIX: Use unique chunk names for each tile!\n",
    "chunk_files = []\n",
    "global_chunk_idx = 0\n",
    "\n",
    "for tile_idx, tif_path in enumerate(tif_to_use):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TILE {tile_idx+1}/{len(tif_to_use)}: {os.path.basename(tif_path)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with rasterio.open(tif_path) as src:\n",
    "        transform = src.transform\n",
    "        height, width = src.height, src.width\n",
    "        n_bands = src.count\n",
    "        \n",
    "        # Calculate chunk size\n",
    "        chunk_size = height // NUM_CHUNKS + 1\n",
    "        print(f\"  Rows: {height}, Chunk size: {chunk_size}\")\n",
    "        \n",
    "        for chunk_idx in range(NUM_CHUNKS):\n",
    "            start_row = chunk_idx * chunk_size\n",
    "            end_row = min(start_row + chunk_size, height)\n",
    "            \n",
    "            if start_row >= height:\n",
    "                break\n",
    "            \n",
    "            records = []\n",
    "            \n",
    "            for row in tqdm(range(start_row, end_row), desc=f\"T{tile_idx+1}C{chunk_idx+1}\"):\n",
    "                window = rasterio.windows.Window(0, row, width, 1)\n",
    "                row_data = src.read(window=window).squeeze(1)\n",
    "                \n",
    "                for col in range(width):\n",
    "                    lng, lat = transform * (col + 0.5, row + 0.5)\n",
    "                    pixel_vals = row_data[:, col]\n",
    "                    \n",
    "                    if np.all(np.isnan(pixel_vals)):\n",
    "                        continue\n",
    "                    \n",
    "                    h3_index = h3.latlng_to_cell(lat, lng, H3_RES)\n",
    "                    rec = {\"h3_index\": h3_index}\n",
    "                    for i, bname in enumerate(band_names[:n_bands]):\n",
    "                        rec[bname] = float(pixel_vals[i])\n",
    "                    records.append(rec)\n",
    "            \n",
    "            # Save chunk with UNIQUE name (tile_chunk)\n",
    "            df_chunk = pd.DataFrame(records)\n",
    "            chunk_file = f\"{PROCESSED}/tile{tile_idx:02d}_chunk{chunk_idx:02d}.parquet\"\n",
    "            df_chunk.to_parquet(chunk_file, index=False)\n",
    "            chunk_files.append(chunk_file)\n",
    "            print(f\"  ✓ {chunk_file.split('/')[-1]}: {len(records):,} records\")\n",
    "            \n",
    "            # Free memory\n",
    "            del records, df_chunk\n",
    "            gc.collect()\n",
    "            global_chunk_idx += 1\n",
    "\n",
    "print(f\"\\n✓ All {len(chunk_files)} chunks saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 50 chunk files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 50/50 [00:02<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating...\n",
      "Total records: 2,872,205\n",
      "Aggregating by H3 index...\n",
      "\n",
      "==================================================\n",
      "DONE: /home/network-lab/Desktop/EWRI/processed/maricopa/embeddings_h3.parquet\n",
      "==================================================\n",
      "H3 cells: 197,573\n",
      "Columns: 513\n"
     ]
    }
   ],
   "source": [
    "# MERGE ALL CHUNKS\n",
    "print(f\"Loading {len(chunk_files)} chunk files...\")\n",
    "\n",
    "chunks = []\n",
    "for f in tqdm(chunk_files, desc=\"Loading\"):\n",
    "    chunks.append(pd.read_parquet(f))\n",
    "\n",
    "print(\"Concatenating...\")\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "del chunks\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(\"Aggregating by H3 index...\")\n",
    "df = df.groupby(\"h3_index\").mean().reset_index()\n",
    "\n",
    "# Save final output\n",
    "output_path = f\"{PROCESSED}/embeddings_h3.parquet\"\n",
    "df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"DONE: {output_path}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"H3 cells: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Deleted 50 chunk files\n"
     ]
    }
   ],
   "source": [
    "# CLEANUP CHUNK FILES\n",
    "for f in chunk_files:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "print(f\"✓ Deleted {len(chunk_files)} chunk files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA QUALITY CHECK\n",
      "==================================================\n",
      "\n",
      "Columns: ['h3_index', 'A00_2017', 'A01_2017', 'A02_2017', 'A03_2017'] ... ['A61_2024', 'A62_2024', 'A63_2024']\n",
      "\n",
      "Data by year:\n",
      "  2017: 64 bands, 100.0% valid\n",
      "  2018: 64 bands, 100.0% valid\n",
      "  2019: 64 bands, 100.0% valid\n",
      "  2020: 64 bands, 100.0% valid\n",
      "  2021: 64 bands, 100.0% valid\n",
      "  2022: 64 bands, 100.0% valid\n",
      "  2023: 64 bands, 100.0% valid\n",
      "  2024: 64 bands, 100.0% valid\n",
      "\n",
      "Value range:\n",
      "  Min: -0.5260\n",
      "  Max: 0.4500\n",
      "  Mean: 0.0053\n"
     ]
    }
   ],
   "source": [
    "# VERIFY OUTPUT\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nColumns: {list(df.columns[:5])} ... {list(df.columns[-3:])}\")\n",
    "\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "print(\"\\nData by year:\")\n",
    "for year in years:\n",
    "    year_cols = [c for c in df.columns if c.endswith(f\"_{year}\")]\n",
    "    if year_cols:\n",
    "        valid_pct = (df[year_cols].notna().sum().sum() / df[year_cols].size) * 100\n",
    "        print(f\"  {year}: {len(year_cols)} bands, {valid_pct:.1f}% valid\")\n",
    "\n",
    "embed_cols = [c for c in df.columns if c != \"h3_index\"]\n",
    "print(f\"\\nValue range:\")\n",
    "print(f\"  Min: {df[embed_cols].min().min():.4f}\")\n",
    "print(f\"  Max: {df[embed_cols].max().max():.4f}\")\n",
    "print(f\"  Mean: {df[embed_cols].mean().mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GEOGRAPHIC COVERAGE\n",
      "==================================================\n",
      "  South: 32.5034°\n",
      "  North: 34.0484°\n",
      "  West:  -113.3369°\n",
      "  East:  -111.0395°\n"
     ]
    }
   ],
   "source": [
    "# GEOGRAPHIC COVERAGE CHECK\n",
    "print(\"\\nGEOGRAPHIC COVERAGE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lats, lngs = [], []\n",
    "for h in df['h3_index'].values:\n",
    "    lat, lng = h3.cell_to_latlng(h)\n",
    "    lats.append(lat)\n",
    "    lngs.append(lng)\n",
    "\n",
    "print(f\"  South: {min(lats):.4f}°\")\n",
    "print(f\"  North: {max(lats):.4f}°\")\n",
    "print(f\"  West:  {min(lngs):.4f}°\")\n",
    "print(f\"  East:  {max(lngs):.4f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
